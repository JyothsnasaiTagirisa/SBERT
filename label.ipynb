{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, InputExample, util, SentencesDataset\n",
    "from sentence_transformers import losses\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_connections(d, sub_d):\n",
    "    file_names = [file.rsplit('\\\\')[-1] for file in glob.glob(f\"text_data/data/{d}_texts/{sub_d}/*.txt\")]\n",
    "    labled_data = {}\n",
    "\n",
    "    for lable in data:\n",
    "        labled_data[lable] = []\n",
    "        for link in data[lable]:\n",
    "            trim_link, page = link.rsplit('/', 1)\n",
    "\n",
    "            if page == '':\n",
    "                page = trim_link.rsplit('/', 1)[1]\n",
    "\n",
    "            if page+\".txt\" in file_names:\n",
    "                labled_data[lable].append(page)\n",
    "    return labled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(file, labled_data):\n",
    "    with open('text_data/labled_data/'+file, 'w') as lf:\n",
    "        json.dump(labled_data, lf, indent=2)\n",
    "\n",
    "        print(\"New json file created in text_data->labled_data directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "britannica aviation\n",
      "New json file created in text_data->labled_data directory.\n",
      "britannica car\n",
      "New json file created in text_data->labled_data directory.\n",
      "britannica ped\n",
      "New json file created in text_data->labled_data directory.\n",
      "wiki aircraft\n",
      "New json file created in text_data->labled_data directory.\n",
      "wiki car\n",
      "New json file created in text_data->labled_data directory.\n",
      "wiki ped\n",
      "New json file created in text_data->labled_data directory.\n"
     ]
    }
   ],
   "source": [
    "# Load Json data\n",
    "\n",
    "for file in glob.glob(f\"text_data/data/*.json\"):\n",
    "    file = file.split('\\\\', 1)[1]\n",
    "    file = file.split('_')\n",
    "    file1 = file[0]\n",
    "    file2 = file[2]\n",
    "    \n",
    "    file = '_'.join(file)\n",
    "    print(file1, file2)\n",
    "    \n",
    "    with open('text_data/data/'+file, 'r') as fp:\n",
    "        data = json.load(fp)\n",
    "        \n",
    "    data = make_connections(file1, file2)\n",
    "    \n",
    "    # Write data to a new file.\n",
    "    write_data(file, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Between Lable and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df = pd.DataFrame({'Brand': pd.Series(dtype='str'), 'Type': pd.Series(dtype='str'), 'Label': pd.Series(dtype='str'), 'File Name':pd.Series(dtype='str'),\n",
    "                              'Text': pd.Series(dtype='str'), 'Score': pd.Series(dtype='float')})\n",
    "\n",
    "\n",
    "\n",
    "# Cosine similarity\n",
    "def cosine_similarity(labled_data, file_name, brand, typ):\n",
    "    global similarity_df\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    i = 0\n",
    "    print(len(labled_data))\n",
    "    for key in labled_data:\n",
    "        i= i+1\n",
    "        for value in labled_data[key]:\n",
    "\n",
    "            with open('text_data/data/'+brand+'_texts/'+typ+'/'+value+'.txt', encoding=\"utf8\") as txt:\n",
    "                d = txt.read().strip()\n",
    "                d = d.replace('\\n', ' ')\n",
    "                d = re.sub('\\s+', ' ', d)\n",
    "                d = d.split(' ')\n",
    "                d = ' '.join(d[:100])\n",
    "                \n",
    "            lable_emb = model.encode(key)\n",
    "            data_emb = model.encode(d)\n",
    "            cos_sim = util.cos_sim(lable_emb, data_emb)\n",
    "            \n",
    "            similarity_df = similarity_df.append({'Brand': brand, 'Type': typ, 'Label': key, 'File Name': value, 'label_type': value+'_'+key, 'Text': d, 'Score': float(cos_sim[0, 0])}, ignore_index=True)\n",
    "        print(key, i)\n",
    "\n",
    "    \n",
    "cosine_similarity(data, file, file1, file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "similarity_df['label_type'] = similarity_df['File Name']+'_'+similarity_df['Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to csv\n",
    "text_score = similarity_df[['label_type', 'Text', 'Score']]\n",
    "\n",
    "# text_score.to_csv('text_score.csv')\n",
    "# similarity_df.to_csv('cosine_sim.csv')\n",
    "text_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare data for training.\n",
    "# brand = 'wiki'\n",
    "# typ = 'ped'\n",
    "# with open('text_data/labled_data/'+brand+'_l1_'+typ+'_link.json', 'r') as fp:\n",
    "#     data = json.load(fp)\n",
    "\n",
    "# input_example = []\n",
    "# sum_c = 0\n",
    "# i=0\n",
    "# label_values = {}\n",
    "\n",
    "# for key in data:\n",
    "#     i= i+1\n",
    "#     examples = []\n",
    "#     for value in data[key]:\n",
    "#         with open('text_data/data/'+brand+'_texts/'+typ+'/'+value+'.txt', encoding=\"utf8\") as txt:\n",
    "#             d = txt.readlines()\n",
    "#             d = ' '.join(d)\n",
    "#             d = d.replace('\\n', '')\n",
    "#             examples.append(d)\n",
    "#             sum_c+=1\n",
    "#     label_values[i] = key\n",
    "#     input_example.append(InputExample(texts=examples[:10], label=float(i/1000)))\n",
    "#     #if i%10==0:\n",
    "#     #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df = pd.read_csv('cosine_sim.csv')\n",
    "similarity_df.dropna(subset=['Text'], how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25380\n"
     ]
    }
   ],
   "source": [
    "# Training Data.\n",
    "text_label = list(zip(list(similarity_df['Text']), list(similarity_df['Score'])))\n",
    "input_example = []\n",
    "\n",
    "for key, val in text_label:\n",
    "    kl = len(key)//2\n",
    "    texts = [key[:kl], key[kl:]]\n",
    "    input_example.append(InputExample(texts = texts, label=val/5))\n",
    "\n",
    "print(len(input_example))\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "\n",
    "# train_dataset = SentencesDataset(input_example, model)\n",
    "\n",
    "train_dataloader = DataLoader(input_example[:1000], shuffle=True, batch_size=64)\n",
    "train_loss = losses.CosineSimilarityLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e3b5d4147e445ebba3792c18d77d57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epoch'), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660e0a3429dc4b2b9320d822c8055e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Iteration'), FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tune the model\n",
    "save_path = 'trained_model-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "train_dataset = model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=1, warmup_steps=100, output_path=save_path)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: DistilBertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text_label = list(zip(list(similarity_df['Text']), list(similarity_df['Score'])))\n",
    "# input_example = list(map(lambda val: InputExample(texts = [val[0]], label=val[1]), text_label))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(input_example, name='sts-test')\n",
    "final = test_evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-faec0869773a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'final' is not defined"
     ]
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = SentenceTransformer(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86362b1d3654e1589c18f910d6a2e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epoch'), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f808340c3a8c4a1e95120ed9167fd637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Iteration'), FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = new_model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=1, warmup_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307\n",
      "plodder 1\n",
      "trafficlane 2\n",
      "interference 3\n",
      "walkway 4\n",
      "crosswalk 5\n",
      "playmates 6\n",
      "walker 7\n",
      "trafficcircle 8\n",
      "stalker 9\n",
      "pathway 10\n",
      "plaintiff 11\n",
      "circulation 12\n",
      "footstep 13\n",
      "nature 14\n",
      "naturestrip 15\n",
      "hike 16\n",
      "bark 17\n",
      "factors 18\n",
      "district 19\n",
      "approach 20\n",
      "rightofway 21\n",
      "negligence 22\n",
      "morning 23\n",
      "roadsurface 24\n",
      "persons 25\n",
      "value 26\n",
      "tramper 27\n",
      "reduction 28\n",
      "totterer 29\n",
      "tripper 30\n",
      "viatecture 31\n",
      "statue 32\n",
      "transportationsystem 33\n",
      "wards 34\n",
      "tunnel 35\n",
      "route 36\n",
      "saunter 37\n",
      "merit 38\n",
      "footway 39\n",
      "level 40\n",
      "eastbound 41\n",
      "marcher 42\n",
      "arterial 43\n",
      "south 44\n",
      "busdepot 45\n",
      "majority 46\n",
      "robinson 47\n",
      "mall 48\n",
      "taxistand 49\n",
      "obstruction 50\n",
      "bicyclerack 51\n",
      "pawn 52\n",
      "prose 53\n",
      "businessdistrict 54\n",
      "separation 55\n",
      "curbless 56\n",
      "survey 57\n",
      "violation 58\n",
      "europe 59\n",
      "experience 60\n",
      "adult 61\n",
      "sense 62\n",
      "space 63\n",
      "scale 64\n",
      "energy 65\n",
      "tree 66\n",
      "hour 67\n",
      "maindrag 68\n",
      "fashion 69\n",
      "pedestrianisation 70\n",
      "exercise 71\n",
      "pedestrial 72\n",
      "gateless 73\n",
      "amount 74\n",
      "prosaic 75\n",
      "non 76\n",
      "walkable 77\n",
      "crossings 78\n",
      "pedestriantraffic 79\n",
      "cobblestone 80\n",
      "transit 81\n",
      "force 82\n",
      "intoxicated 83\n",
      "account 84\n",
      "stroll 85\n",
      "life 86\n",
      "passerby 87\n",
      "form 88\n",
      "study 89\n",
      "blindcurve 90\n",
      "boots 91\n",
      "oncoming 92\n",
      "bystander 93\n",
      "west 94\n",
      "bedroomcommunity 95\n",
      "refuge 96\n",
      "yorks 97\n",
      "ambler 98\n",
      "slogger 99\n",
      "pointduty 100\n",
      "stroller 101\n",
      "running 102\n",
      "passage 103\n",
      "rambler 104\n",
      "injuries 105\n",
      "maze 106\n",
      "subwaytrain 107\n",
      "gait 108\n",
      "quality 109\n",
      "safetyisland 110\n",
      "bicyclist 111\n",
      "pedestrianize 112\n",
      "tour 113\n",
      "purposes 114\n",
      "score 115\n",
      "gephyrophobia 116\n",
      "density 117\n",
      "skateboards 118\n",
      "overpasses 119\n",
      "comparison 120\n",
      "frontageroad 121\n",
      "prosy 122\n",
      "entrance 123\n",
      "skills 124\n",
      "town 125\n",
      "bike 126\n",
      "neighborhoods 127\n",
      "stamper 128\n",
      "network 129\n",
      "pastures 130\n",
      "facilities 131\n",
      "promenade 132\n",
      "precinct 133\n",
      "carson 134\n",
      "tollbar 135\n",
      "passer 136\n",
      "soul 137\n",
      "gibe 138\n",
      "underpass 139\n",
      "passer-by 140\n",
      "drivearound 141\n",
      "car 142\n",
      "crashbarrier 143\n",
      "footpath 144\n",
      "block 145\n",
      "railroadtrack 146\n",
      "earthbound 147\n",
      "way 148\n",
      "women 149\n",
      "flounce 150\n",
      "air 151\n",
      "rights 152\n",
      "reverie 153\n",
      "behavior 154\n",
      "sidewalk 155\n",
      "trafficwarden 156\n",
      "environment 157\n",
      "hiker 158\n",
      "flow 159\n",
      "dress 160\n",
      "kind 161\n",
      "localroad 162\n",
      "chance 163\n",
      "arterialroad 164\n",
      "roadhog 165\n",
      "crossstreet 166\n",
      "verse 167\n",
      "limper 168\n",
      "lives 169\n",
      "railwayline 170\n",
      "signals 171\n",
      "walkabout 172\n",
      "property 173\n",
      "accessroad 174\n",
      "attention 175\n",
      "cycle 176\n",
      "activity 177\n",
      "status 178\n",
      "footbridge 179\n",
      "area 180\n",
      "gate 181\n",
      "year 182\n",
      "hobbler 183\n",
      "cantileverbridge 184\n",
      "mode 185\n",
      "path 186\n",
      "ambulatory 187\n",
      "streetcorner 188\n",
      "trafficisland 189\n",
      "underpasses 190\n",
      "trafficcop 191\n",
      "movement 192\n",
      "london 193\n",
      "corridor 194\n",
      "wheelaround 195\n",
      "sage 196\n",
      "building 197\n",
      "wheelchair 198\n",
      "canoe 199\n",
      "pattens 200\n",
      "uninteresting 201\n",
      "provision 202\n",
      "woman 203\n",
      "treader 204\n",
      "powers 205\n",
      "treelawn 206\n",
      "volume 207\n",
      "development 208\n",
      "gumwood 209\n",
      "character 210\n",
      "island 211\n",
      "cyclist 212\n",
      "subwaystation 213\n",
      "wayfarer 214\n",
      "shopping 215\n",
      "warning 216\n",
      "mankind 217\n",
      "racewalking 218\n",
      "peripatetic 219\n",
      "paviage 220\n",
      "protected 221\n",
      "lack 222\n",
      "congested 223\n",
      "trolleycar 224\n",
      "belishabeacon 225\n",
      "series 226\n",
      "death 227\n",
      "traversable 228\n",
      "strider 229\n",
      "staggerer 230\n",
      "hardshoulder 231\n",
      "child 232\n",
      "guide 233\n",
      "walking 234\n",
      "collision 235\n",
      "connections 236\n",
      "hiking 237\n",
      "concourse 238\n",
      "variety 239\n",
      "heart 240\n",
      "amble 241\n",
      "perambulation 242\n",
      "foot 243\n",
      "duty 244\n",
      "creation 245\n",
      "protégé 246\n",
      "childhood 247\n",
      "lane 248\n",
      "elevated 249\n",
      "roundabout 250\n",
      "sheltered 251\n",
      "percent 252\n",
      "servicearea 253\n",
      "portion 254\n",
      "link 255\n",
      "amenities 256\n",
      "sensation 257\n",
      "effect 258\n",
      "pavement 259\n",
      "streetsign 260\n",
      "tollcollector 261\n",
      "undergroundrailway 262\n",
      "shuffler 263\n",
      "thoroughfare 264\n",
      "traveller 265\n",
      "manner 266\n",
      "pattern 267\n",
      "interstate 268\n",
      "emphasis 269\n",
      "activities 270\n",
      "motorized 271\n",
      "permanentway 272\n",
      "task 273\n",
      "type 274\n",
      "trudge 275\n",
      "story 276\n",
      "fatalities 277\n",
      "zone 278\n",
      "yellowline 279\n",
      "footer 280\n",
      "traveler 281\n",
      "pavementartist 282\n",
      "student 283\n",
      "realism 284\n",
      "bed 285\n",
      "tollbridge 286\n",
      "plaza 287\n",
      "support 288\n",
      "overpass 289\n",
      "swaggerer 290\n",
      "routine 291\n",
      "edge 292\n",
      "motorist 293\n",
      "vehiculation 294\n",
      "feats 295\n",
      "passersby 296\n",
      "excursion 297\n",
      "country 298\n",
      "analyses 299\n",
      "transportation 300\n",
      "scenicroute 301\n",
      "journey 302\n",
      "landscaped 303\n",
      "solace 304\n",
      "relation 305\n",
      "crusoe 306\n",
      "vehiculartraffic 307\n"
     ]
    }
   ],
   "source": [
    "similarity_df1 = pd.DataFrame({'Brand': pd.Series(dtype='str'), 'Type': pd.Series(dtype='str'), 'Label': pd.Series(dtype='str'), 'File Name':pd.Series(dtype='str'),\n",
    "                              'Text': pd.Series(dtype='str'), 'Score': pd.Series(dtype='float')})\n",
    "\n",
    "def cosine_similarity1(labled_data, file_name, brand, typ):\n",
    "    global similarity_df1\n",
    "    global new_model\n",
    "    i = 0\n",
    "    print(len(labled_data))\n",
    "    for key in labled_data:\n",
    "        i= i+1\n",
    "        for value in labled_data[key]:\n",
    "\n",
    "            with open('text_data/data/'+brand+'_texts/'+typ+'/'+value+'.txt', encoding=\"utf8\") as txt:\n",
    "                d = txt.read().strip()\n",
    "                d = d.replace('\\n', ' ')\n",
    "                d = re.sub('\\s+', ' ', d)\n",
    "                d = d.split(' ')\n",
    "                d = ' '.join(d[:100])\n",
    "                \n",
    "            lable_emb = new_model.encode(key)\n",
    "            data_emb = new_model.encode(d)\n",
    "            cos_sim = util.cos_sim(lable_emb, data_emb)\n",
    "            \n",
    "            similarity_df1 = similarity_df1.append({'Brand': brand, 'Type': typ, 'Label': key, 'File Name': value, 'label_type': value+'_'+key, 'Text': d, 'Score': float(cos_sim[0, 0])}, ignore_index=True)\n",
    "        print(key, i)\n",
    "\n",
    "    \n",
    "cosine_similarity1(data, file, file1, file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df1.to_csv('new_cosine_sim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_type</th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>List_of_police-related_slang_terms_plodder</td>\n",
       "      <td>Many police-related slang terms exist for poli...</td>\n",
       "      <td>-0.002582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charles_Darwin_plodder</td>\n",
       "      <td>Professional institution: Charles Robert Darwi...</td>\n",
       "      <td>-0.064479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Archive_17_plodder</td>\n",
       "      <td>I propose we remove the Notification is to be ...</td>\n",
       "      <td>0.057894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lane_trafficlane</td>\n",
       "      <td>In road transport, a lane is part of a roadway...</td>\n",
       "      <td>0.414688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>High-occupancy_vehicle_lane_trafficlane</td>\n",
       "      <td>A high-occupancy vehicle lane (also known as a...</td>\n",
       "      <td>0.353449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25390</th>\n",
       "      <td>Speed_limit_vehiculartraffic</td>\n",
       "      <td>Speed limits on road traffic, as used in most ...</td>\n",
       "      <td>0.169553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25391</th>\n",
       "      <td>Reversible_lane_vehiculartraffic</td>\n",
       "      <td>A reversible lane (British English: tidal flow...</td>\n",
       "      <td>0.124376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25392</th>\n",
       "      <td>Road_signs_in_Italy_vehiculartraffic</td>\n",
       "      <td>Road signs in Italy conform to the general pat...</td>\n",
       "      <td>0.187801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25393</th>\n",
       "      <td>Road_surface_vehiculartraffic</td>\n",
       "      <td>A road surface (British English), or pavement ...</td>\n",
       "      <td>0.289680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25394</th>\n",
       "      <td>Road_signs_in_the_United_Kingdom_vehiculartraffic</td>\n",
       "      <td>Road signs in the United Kingdom and in its as...</td>\n",
       "      <td>0.307473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25395 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              label_type  \\\n",
       "0             List_of_police-related_slang_terms_plodder   \n",
       "1                                 Charles_Darwin_plodder   \n",
       "2                                     Archive_17_plodder   \n",
       "3                                       Lane_trafficlane   \n",
       "4                High-occupancy_vehicle_lane_trafficlane   \n",
       "...                                                  ...   \n",
       "25390                       Speed_limit_vehiculartraffic   \n",
       "25391                   Reversible_lane_vehiculartraffic   \n",
       "25392               Road_signs_in_Italy_vehiculartraffic   \n",
       "25393                      Road_surface_vehiculartraffic   \n",
       "25394  Road_signs_in_the_United_Kingdom_vehiculartraffic   \n",
       "\n",
       "                                                    Text     Score  \n",
       "0      Many police-related slang terms exist for poli... -0.002582  \n",
       "1      Professional institution: Charles Robert Darwi... -0.064479  \n",
       "2      I propose we remove the Notification is to be ...  0.057894  \n",
       "3      In road transport, a lane is part of a roadway...  0.414688  \n",
       "4      A high-occupancy vehicle lane (also known as a...  0.353449  \n",
       "...                                                  ...       ...  \n",
       "25390  Speed limits on road traffic, as used in most ...  0.169553  \n",
       "25391  A reversible lane (British English: tidal flow...  0.124376  \n",
       "25392  Road signs in Italy conform to the general pat...  0.187801  \n",
       "25393  A road surface (British English), or pavement ...  0.289680  \n",
       "25394  Road signs in the United Kingdom and in its as...  0.307473  \n",
       "\n",
       "[25395 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to csv\n",
    "text_score = similarity_df1[['label_type', 'Text', 'Score']]\n",
    "text_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
